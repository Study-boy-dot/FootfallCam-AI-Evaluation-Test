{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b2452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tracker import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f387fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motionDetection():\n",
    "    cap = cv.VideoCapture('sample.mp4')\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    tracker = EuclideanDistTracker()\n",
    "    \n",
    "    object_detector = cv.createBackgroundSubtractorMOG2(history=100, varThreshold=40)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        mask1 = object_detector.apply(frame1)\n",
    "        mask2 = object_detector.apply(frame2)\n",
    "\n",
    "        diff = cv.absdiff(frame1, frame2)\n",
    "        diff_gray = cv.cvtColor(diff, cv.COLOR_BGR2GRAY)\n",
    "        blur = cv.GaussianBlur(diff_gray, (5, 5), 0)\n",
    "        _, thresh = cv.threshold(blur, 20, 255, cv.THRESH_BINARY)\n",
    "        dilated = cv.dilate(thresh, None, iterations=3)\n",
    "        contours, _ = cv.findContours(dilated, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        detection = []\n",
    "        for contour in contours:\n",
    "            if cv.contourArea(contour) < 900:\n",
    "                continue\n",
    "            (x, y, w, h) = cv.boundingRect(contour)\n",
    "            detection.append([x, y, w, h])\n",
    "            # cv.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "        # Object Tracking\n",
    "        boxes_ids = tracker.update(detection)\n",
    "        for box_id in boxes_ids:\n",
    "            x, y, w, h, id = box_id\n",
    "            cv.putText(frame1, str(id), (x, y - 15), cv.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "            cv.rectangle(frame1, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "        cv.imshow('Video', frame1)\n",
    "        frame1 = frame2\n",
    "        ret, frame2 = cap.read()\n",
    "        \n",
    "        if cv.waitKey(50) == 27:\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4f1dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 960)\n",
      "(720, 960)\n",
      "{0: (225, 477), 1: (136, 422), 2: (355, 651)}\n",
      "{0: (225, 477), 1: (136, 427), 2: (355, 651)}\n",
      "(720, 960)\n",
      "{2: (339, 639), 0: (225, 477), 1: (136, 427)}\n",
      "{2: (339, 639), 0: (223, 480), 1: (136, 427)}\n",
      "{2: (339, 639), 0: (223, 480), 1: (127, 431)}\n",
      "(720, 960)\n",
      "{2: (331, 643), 0: (223, 480), 1: (127, 431)}\n",
      "{2: (331, 643), 0: (223, 468), 1: (127, 431)}\n",
      "{2: (331, 643), 0: (223, 468), 1: (116, 425), 3: (182, 426)}\n",
      "(720, 960)\n",
      "{2: (331, 643), 0: (217, 481), 3: (182, 426), 1: (116, 425), 4: (271, 410), 5: (44, 234), 6: (248, 224)}\n",
      "{2: (331, 643), 0: (217, 481), 3: (182, 426), 1: (120, 428), 4: (271, 410), 5: (44, 234), 6: (248, 224)}\n",
      "{2: (331, 643), 0: (217, 481), 3: (182, 426), 1: (120, 428), 4: (271, 410), 5: (48, 235), 6: (248, 224)}\n",
      "(720, 960)\n",
      "{0: (217, 481), 1: (130, 423), 5: (48, 235)}\n",
      "{0: (217, 481), 1: (130, 423), 5: (42, 251)}\n",
      "(720, 960)\n",
      "{1: (113, 427), 5: (42, 251), 7: (244, 204)}\n",
      "{1: (113, 427), 5: (42, 245), 7: (244, 204)}\n",
      "(720, 960)\n",
      "{1: (113, 427), 5: (42, 245), 8: (131, 223), 9: (209, 463), 10: (282, 423)}\n",
      "{1: (113, 427), 5: (42, 249), 8: (131, 223), 9: (209, 463), 10: (282, 423)}\n",
      "(720, 960)\n",
      "{9: (209, 463), 10: (282, 423), 8: (131, 223), 5: (41, 272)}\n",
      "(720, 960)\n",
      "{5: (41, 272), 11: (55, 212)}\n",
      "(720, 960)\n",
      "{11: (59, 205), 12: (186, 437), 13: (273, 414), 14: (126, 218)}\n",
      "(720, 960)\n",
      "{12: (186, 437), 13: (282, 410), 14: (126, 218), 11: (59, 205), 15: (248, 201)}\n",
      "{12: (186, 437), 13: (282, 410), 14: (125, 219), 11: (59, 205), 15: (248, 201)}\n",
      "{12: (186, 437), 13: (282, 410), 14: (125, 219), 11: (62, 206), 15: (248, 201)}\n",
      "{12: (186, 437), 13: (282, 410), 14: (125, 219), 11: (62, 206), 15: (241, 193)}\n",
      "(720, 960)\n",
      "{13: (282, 410), 14: (125, 219), 11: (65, 199), 15: (241, 193)}\n",
      "{13: (282, 410), 14: (125, 219), 11: (65, 199), 15: (249, 205)}\n",
      "(720, 960)\n",
      "{11: (70, 195), 15: (249, 205), 16: (198, 424), 17: (274, 401), 18: (650, 303)}\n",
      "{11: (70, 195), 15: (255, 185), 16: (198, 424), 17: (274, 401), 18: (650, 303)}\n",
      "(720, 960)\n",
      "{16: (198, 424), 17: (274, 401), 18: (651, 304), 11: (70, 195), 15: (255, 185), 19: (232, 486), 20: (68, 464), 21: (224, 421)}\n",
      "{16: (198, 424), 17: (274, 401), 18: (651, 304), 11: (70, 195), 15: (246, 202), 19: (232, 486), 20: (68, 464), 21: (224, 421), 22: (41, 278), 23: (761, 189)}\n",
      "(720, 960)\n",
      "{19: (211, 487), 20: (68, 464), 21: (224, 421), 18: (651, 304), 22: (41, 278), 23: (761, 189), 15: (246, 202), 24: (95, 198)}\n",
      "{19: (211, 487), 20: (68, 464), 21: (224, 421), 18: (651, 304), 22: (43, 273), 23: (761, 189), 15: (246, 202), 24: (95, 198), 25: (269, 396)}\n",
      "{19: (211, 487), 20: (68, 464), 21: (224, 421), 18: (651, 304), 22: (43, 273), 23: (762, 183), 15: (246, 202), 24: (95, 198), 25: (269, 396)}\n",
      "{19: (211, 487), 20: (68, 464), 21: (224, 421), 18: (651, 304), 22: (43, 273), 23: (762, 183), 15: (248, 182), 24: (95, 198), 25: (269, 396)}\n",
      "{19: (211, 487), 20: (68, 464), 21: (224, 421), 18: (651, 304), 22: (43, 273), 23: (762, 183), 15: (248, 182), 24: (85, 181), 25: (269, 396)}\n",
      "(720, 960)\n",
      "{19: (208, 472), 25: (269, 396), 22: (43, 273), 23: (762, 183), 15: (248, 182), 24: (85, 181)}\n",
      "{19: (208, 472), 25: (269, 396), 22: (43, 260), 23: (762, 183), 15: (248, 182), 24: (85, 181)}\n",
      "{19: (208, 472), 25: (269, 396), 22: (43, 260), 23: (762, 183), 15: (248, 182), 24: (90, 178)}\n",
      "(720, 960)\n",
      "{19: (203, 462), 22: (43, 260), 24: (90, 178)}\n",
      "{19: (203, 462), 22: (43, 254), 24: (90, 178), 26: (285, 426)}\n",
      "{19: (203, 462), 22: (43, 254), 24: (104, 175), 26: (285, 426), 27: (762, 178), 28: (256, 188)}\n",
      "(720, 960)\n",
      "{19: (218, 470), 26: (285, 426), 22: (43, 254), 27: (762, 178), 28: (256, 188), 24: (104, 175), 29: (248, 117)}\n",
      "{19: (218, 470), 26: (285, 426), 22: (43, 254), 27: (762, 178), 28: (256, 188), 24: (107, 167), 29: (248, 117)}\n",
      "{19: (218, 470), 26: (285, 426), 22: (43, 254), 27: (762, 178), 28: (256, 188), 24: (107, 167), 29: (226, 114), 30: (277, 115)}\n",
      "(720, 960)\n",
      "{19: (211, 466), 24: (107, 167), 30: (277, 115), 29: (226, 114)}\n",
      "{19: (211, 466), 24: (107, 164), 30: (277, 115), 29: (226, 114), 31: (270, 397), 32: (253, 183)}\n",
      "{19: (211, 466), 24: (107, 164), 30: (265, 105), 29: (226, 114), 31: (270, 397), 32: (253, 183)}\n",
      "{19: (211, 466), 24: (107, 164), 30: (265, 105), 29: (227, 107), 31: (270, 397), 32: (253, 183)}\n",
      "(720, 960)\n",
      "{19: (211, 466), 31: (270, 397), 32: (252, 183), 24: (107, 164), 30: (265, 105), 29: (227, 107), 33: (61, 472), 34: (223, 438)}\n",
      "{19: (211, 466), 31: (270, 397), 32: (252, 183), 24: (112, 163), 30: (265, 105), 29: (227, 107), 33: (61, 472), 34: (223, 438)}\n",
      "{19: (211, 466), 31: (270, 397), 32: (252, 183), 24: (112, 163), 30: (248, 106), 29: (227, 107), 33: (61, 472), 34: (223, 438)}\n",
      "(720, 960)\n",
      "{33: (61, 472), 34: (223, 438), 32: (252, 179), 24: (112, 163), 30: (248, 106), 35: (211, 488), 36: (185, 437), 37: (260, 408)}\n",
      "{33: (61, 472), 34: (223, 438), 32: (252, 179), 24: (125, 158), 30: (248, 106), 35: (211, 488), 36: (185, 437), 37: (260, 408)}\n",
      "(720, 960)\n",
      "{35: (211, 488), 36: (199, 456), 37: (260, 408), 32: (252, 179), 24: (125, 158)}\n",
      "{35: (211, 488), 36: (199, 456), 37: (257, 404), 32: (252, 179), 24: (125, 158)}\n",
      "{35: (211, 488), 36: (199, 456), 37: (257, 404), 32: (254, 178), 24: (125, 158), 38: (44, 264), 39: (747, 173)}\n",
      "{35: (211, 488), 36: (199, 456), 37: (257, 404), 32: (254, 178), 24: (126, 152), 38: (44, 264), 39: (747, 173)}\n",
      "(720, 960)\n",
      "{36: (204, 451), 37: (257, 404), 38: (44, 264), 39: (747, 173), 32: (254, 178), 24: (126, 152)}\n",
      "{36: (204, 451), 37: (262, 387), 38: (44, 264), 39: (747, 173), 32: (254, 178), 24: (126, 152)}\n",
      "{36: (204, 451), 37: (262, 387), 38: (44, 272), 39: (747, 173), 32: (254, 178), 24: (126, 152)}\n",
      "{36: (204, 451), 37: (262, 387), 38: (44, 272), 39: (747, 173), 32: (247, 196), 24: (126, 152), 40: (127, 220)}\n",
      "{36: (204, 451), 37: (262, 387), 38: (44, 272), 39: (742, 184), 32: (247, 196), 24: (126, 152), 40: (127, 220)}\n",
      "{36: (204, 451), 37: (262, 387), 38: (44, 272), 39: (742, 184), 32: (247, 196), 24: (134, 149), 40: (127, 220)}\n",
      "(720, 960)\n",
      "{36: (193, 467), 37: (262, 387), 38: (44, 272), 40: (127, 220), 32: (247, 196), 39: (742, 184), 24: (134, 149)}\n",
      "{36: (193, 467), 37: (262, 387), 38: (43, 278), 40: (127, 220), 32: (247, 196), 39: (742, 184), 24: (134, 149)}\n",
      "{36: (193, 467), 37: (262, 387), 38: (43, 278), 40: (127, 220), 32: (241, 206), 39: (742, 184), 24: (134, 149)}\n",
      "{36: (193, 467), 37: (262, 387), 38: (43, 278), 40: (127, 220), 32: (241, 206), 39: (744, 179), 24: (134, 149)}\n",
      "{36: (193, 467), 37: (262, 387), 38: (43, 278), 40: (127, 220), 32: (241, 206), 39: (744, 179), 24: (136, 145)}\n",
      "(720, 960)\n",
      "{36: (191, 468), 38: (43, 278), 32: (241, 206), 39: (744, 179), 24: (136, 145)}\n",
      "{36: (191, 468), 38: (27, 275), 32: (241, 206), 39: (744, 179), 24: (136, 145), 41: (284, 430), 42: (254, 391)}\n",
      "{36: (191, 468), 38: (27, 275), 32: (241, 206), 39: (746, 169), 24: (136, 145), 41: (284, 430), 42: (254, 391), 43: (144, 234), 44: (265, 188)}\n",
      "{36: (191, 468), 38: (27, 275), 32: (241, 206), 39: (746, 169), 24: (138, 142), 41: (284, 430), 42: (254, 391), 43: (144, 234), 44: (265, 188)}\n",
      "(720, 960)\n",
      "{36: (210, 474), 41: (284, 430), 42: (254, 391), 38: (27, 275), 43: (144, 234), 44: (265, 188), 39: (746, 169), 24: (138, 142)}\n",
      "{36: (210, 474), 41: (284, 430), 42: (255, 387), 38: (27, 275), 43: (144, 234), 44: (265, 188), 39: (746, 169), 24: (138, 142), 45: (184, 415)}\n",
      "{36: (210, 474), 41: (284, 430), 42: (255, 387), 38: (27, 275), 43: (147, 237), 44: (265, 188), 39: (746, 169), 24: (138, 142), 45: (184, 415)}\n",
      "{36: (210, 474), 41: (284, 430), 42: (255, 387), 38: (27, 275), 43: (147, 237), 44: (263, 183), 39: (746, 169), 24: (138, 142), 45: (184, 415)}\n",
      "{36: (210, 474), 41: (284, 430), 42: (255, 387), 38: (27, 275), 43: (147, 237), 44: (263, 183), 39: (764, 170), 24: (138, 142), 45: (184, 415)}\n",
      "{36: (210, 474), 41: (284, 430), 42: (255, 387), 38: (27, 275), 43: (147, 237), 44: (263, 183), 39: (764, 170), 24: (144, 138), 45: (184, 415)}\n",
      "(720, 960)\n",
      "{36: (196, 480), 45: (184, 415), 42: (255, 387), 43: (147, 237), 44: (263, 183), 39: (764, 170), 24: (144, 138), 46: (262, 99), 47: (373, 705)}\n",
      "{36: (196, 480), 45: (184, 415), 42: (255, 387), 43: (144, 238), 44: (263, 183), 39: (764, 170), 24: (144, 138), 46: (262, 99), 47: (373, 705), 48: (223, 410)}\n",
      "{36: (196, 480), 45: (184, 415), 42: (255, 387), 43: (144, 238), 44: (263, 183), 39: (754, 162), 24: (144, 138), 46: (262, 99), 47: (373, 705), 48: (223, 410)}\n",
      "(720, 960)\n",
      "{47: (373, 705), 36: (196, 480), 48: (221, 407), 43: (144, 238), 39: (754, 162), 49: (205, 135)}\n",
      "{47: (373, 705), 36: (196, 480), 48: (221, 407), 43: (144, 238), 39: (770, 161), 49: (205, 135)}\n",
      "(720, 960)\n",
      "{48: (219, 410), 39: (770, 161), 50: (166, 130), 51: (196, 485)}\n",
      "{48: (219, 410), 39: (753, 154), 50: (166, 130), 51: (196, 485), 52: (270, 174)}\n",
      "{48: (219, 410), 39: (753, 154), 50: (180, 127), 51: (196, 485), 52: (270, 174)}\n",
      "(720, 960)\n",
      "{51: (206, 478), 48: (219, 410), 52: (270, 174), 39: (753, 154), 50: (180, 127)}\n",
      "{51: (206, 478), 48: (210, 400), 52: (270, 174), 39: (753, 154), 50: (180, 127)}\n",
      "{51: (206, 478), 48: (210, 400), 52: (270, 174), 39: (770, 157), 50: (180, 127), 53: (146, 237)}\n",
      "{51: (206, 478), 48: (210, 400), 52: (270, 174), 39: (770, 157), 50: (187, 132), 53: (146, 237)}\n",
      "(720, 960)\n",
      "{51: (200, 479), 48: (210, 400), 53: (146, 237), 39: (770, 157), 50: (187, 132)}\n",
      "{51: (200, 479), 48: (210, 400), 53: (149, 232), 39: (770, 157), 50: (187, 132), 54: (169, 418), 55: (243, 380)}\n",
      "{51: (200, 479), 48: (210, 400), 53: (149, 232), 39: (774, 148), 50: (187, 132), 54: (169, 418), 55: (243, 380)}\n",
      "{51: (200, 479), 48: (210, 400), 53: (149, 232), 39: (774, 148), 50: (191, 135), 54: (169, 418), 55: (243, 380)}\n",
      "(720, 960)\n",
      "{51: (200, 479), 54: (169, 418), 55: (243, 380), 53: (149, 227), 39: (774, 148), 50: (191, 135), 56: (220, 460), 57: (209, 397), 58: (34, 276)}\n",
      "{51: (200, 479), 54: (169, 418), 55: (243, 380), 53: (149, 227), 39: (760, 142), 50: (191, 135), 56: (220, 460), 57: (209, 397), 58: (34, 276), 59: (271, 182)}\n",
      "{51: (200, 479), 54: (169, 418), 55: (243, 380), 53: (149, 227), 39: (760, 142), 50: (200, 136), 56: (220, 460), 57: (209, 397), 58: (34, 276), 59: (271, 182)}\n",
      "(720, 960)\n",
      "{56: (220, 460), 57: (220, 386), 58: (34, 276), 53: (149, 227), 59: (271, 182), 39: (760, 142), 50: (200, 136), 60: (355, 644), 61: (190, 476), 62: (284, 432)}\n",
      "{56: (220, 460), 57: (220, 386), 58: (41, 277), 53: (149, 227), 59: (271, 182), 39: (760, 142), 50: (200, 136), 60: (355, 644), 61: (190, 476), 62: (284, 432)}\n",
      "{56: (220, 460), 57: (220, 386), 58: (41, 277), 53: (149, 227), 59: (265, 175), 39: (760, 142), 50: (200, 136), 60: (355, 644), 61: (190, 476), 62: (284, 432)}\n",
      "{56: (220, 460), 57: (220, 386), 58: (41, 277), 53: (149, 227), 59: (265, 175), 39: (766, 142), 50: (200, 136), 60: (355, 644), 61: (190, 476), 62: (284, 432)}\n",
      "{56: (220, 460), 57: (220, 386), 58: (41, 277), 53: (149, 227), 59: (265, 175), 39: (766, 142), 50: (206, 128), 60: (355, 644), 61: (190, 476), 62: (284, 432)}\n",
      "(720, 960)\n",
      "{60: (337, 643), 61: (190, 476), 62: (284, 432), 57: (220, 386), 58: (41, 277), 59: (265, 175), 39: (766, 142), 50: (206, 128)}\n",
      "{60: (337, 643), 61: (197, 479), 62: (284, 432), 57: (220, 386), 58: (41, 277), 59: (265, 175), 39: (766, 142), 50: (206, 128)}\n",
      "{60: (337, 643), 61: (197, 479), 62: (281, 433), 57: (220, 386), 58: (41, 277), 59: (265, 175), 39: (766, 142), 50: (206, 128)}\n",
      "{60: (337, 643), 61: (197, 479), 62: (281, 433), 57: (207, 397), 58: (41, 277), 59: (265, 175), 39: (766, 142), 50: (206, 128)}\n",
      "{60: (337, 643), 61: (197, 479), 62: (281, 433), 57: (207, 397), 58: (40, 273), 59: (265, 175), 39: (766, 142), 50: (206, 128)}\n",
      "{60: (337, 643), 61: (197, 479), 62: (281, 433), 57: (207, 397), 58: (40, 273), 59: (265, 175), 39: (762, 140), 50: (206, 128)}\n",
      "(720, 960)\n",
      "{60: (353, 655), 61: (197, 479), 62: (281, 433), 57: (207, 397), 58: (40, 273), 39: (762, 140), 63: (222, 153)}\n",
      "{60: (353, 655), 61: (197, 479), 62: (281, 433), 57: (204, 396), 58: (40, 273), 39: (762, 140), 63: (222, 153), 64: (218, 493)}\n",
      "{60: (353, 655), 61: (197, 479), 62: (281, 433), 57: (204, 396), 58: (40, 273), 39: (762, 136), 63: (222, 153), 64: (218, 493), 65: (273, 174)}\n",
      "(720, 960)\n",
      "{60: (353, 655), 64: (221, 495), 57: (204, 396), 65: (273, 174), 39: (762, 136), 66: (214, 118)}\n",
      "{60: (353, 655), 64: (221, 495), 57: (218, 404), 65: (273, 174), 39: (762, 136), 66: (214, 118), 67: (57, 462)}\n",
      "{60: (353, 655), 64: (221, 495), 57: (218, 404), 65: (273, 174), 39: (763, 145), 66: (214, 118), 67: (57, 462)}\n"
     ]
    }
   ],
   "source": [
    "# motionDetection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a74c0e",
   "metadata": {},
   "source": [
    "## Save images in specific frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba53dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = 'images'\n",
    "# file_name = 'image'\n",
    "\n",
    "# cap = cv.VideoCapture('sample.mp4')\n",
    "\n",
    "# # Make sure the 'images' directory exists\n",
    "# os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# i = 0\n",
    "# frame_idx = 0\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     if frame_idx < 567 and frame_idx > 400 or frame_idx > 800 and frame_idx < 967:\n",
    "#         path = os.path.join(dir_path, f'{file_name}{i:04d}.png')\n",
    "#         cv.imwrite(path, frame)\n",
    "#         i += 1\n",
    "#     frame_idx += 1\n",
    "\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865f085",
   "metadata": {},
   "source": [
    "## Crop image horizontally half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d07655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(input_path, output_path, middle_point):\n",
    "    if not os.path.exists(input_path):\n",
    "        print('Directory does not exist')\n",
    "        return\n",
    "    \n",
    "    files = os.listdir(input_path)\n",
    "    for i, file in enumerate(files):\n",
    "        # read images\n",
    "        i_path = os.path.join(input_path, file)\n",
    "        image = cv.imread(i_path)\n",
    "\n",
    "        # Image process\n",
    "        img1, img2 = crop_image(image, middle_point)\n",
    "\n",
    "        # save images\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        o_path1 = os.path.join(output_path, f'image{i}_up.jpg')\n",
    "        o_path2 = os.path.join(output_path, f'image{i}_down.jpg')\n",
    "        cv.imwrite(o_path1, img1)\n",
    "        cv.imwrite(o_path2, img2)\n",
    "\n",
    "def crop_image(image, middle_point):\n",
    "    # Image process\n",
    "    # height = image.shape[0] // 2\n",
    "    img1 = image[0: middle_point, :, :]\n",
    "    img2 = image[middle_point:, :, :]\n",
    "    img2 = cv.rotate(img2, cv.ROTATE_180)\n",
    "\n",
    "    return img1, img2\n",
    "\n",
    "# dir_path = 'images'\n",
    "# crop_images(dir_path, 'crop_images', 315)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f1d508",
   "metadata": {},
   "source": [
    "## Fisheye frame undistorted\n",
    "Cannot get the correct intrinsic matrix and distortion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de076305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a frame from your fisheye camera\n",
    "# frame = cv.imread('images\\image0030.png')\n",
    "# if frame is None:\n",
    "#     print('frame is not loaded')\n",
    "    \n",
    "# # Fisheye camera calibration parameters\n",
    "# K = np.array([[556.20835637, 0, 256.88266933],\n",
    "#               [0, 556.11754229, 259.93875071],\n",
    "#               [0, 0, 1]])\n",
    "\n",
    "# D = np.array([-0.13280831, 0.12408884, -0.00057422, 0.00046171, -0.07185642])\n",
    "\n",
    "# # Undistort the frame\n",
    "# undistorted_frame = cv.undistort(frame, K, D)\n",
    "\n",
    "# cv.imshow('Undistorted frame', undistorted_frame)\n",
    "# cv.imshow('frame', frame)\n",
    "\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f37462",
   "metadata": {},
   "source": [
    "## Transform image with warpPerspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_frame(input):\n",
    "    left_pts1 = np.float32([[126, 130], [514, 42], [126, 593], [514, 687]])\n",
    "    left_pts2 =np.float32([[0, 0], [400, 0], [0, 640], [400, 640]])\n",
    "\n",
    "    right_pts1 = np.float32([[514, 42], [730, 96], [514, 687], [730, 640]])\n",
    "    right_pts2 = np.float32([[0, 0], [200, 0], [0, 640], [200, 640]])\n",
    "\n",
    "    left_M = cv.getPerspectiveTransform(left_pts1, left_pts2)\n",
    "    right_M = cv.getPerspectiveTransform(right_pts1, right_pts2)\n",
    "\n",
    "    # input = cv.imread('images\\image0001.png')\n",
    "    left_out = cv.warpPerspective(input, left_M, (400, 640))\n",
    "    right_out = cv.warpPerspective(input, right_M, (200, 640))\n",
    "\n",
    "    # Merge two images\n",
    "    output = np.hstack((left_out, right_out))\n",
    "    # output = cv.resize(output, (input.shape[1], input.shape[0]), interpolation=cv.INTER_AREA)\n",
    "    \n",
    "    # cv.imshow('Left Output', left_out)\n",
    "    # cv.imshow('Right Output', right_out)\n",
    "    # cv.imshow('Output', output)\n",
    "\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca6aa9a",
   "metadata": {},
   "source": [
    "## Modelscope model\n",
    "human head prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fd4db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 11:45:38,386 - modelscope - WARNING - Model revision not specified, use revision: v1.1.1\n",
      "2023-11-02 11:45:38,972 - modelscope - INFO - initiate model from C:\\Users\\junee\\.cache\\modelscope\\hub\\damo\\cv_tinynas_head-detection_damoyolo\n",
      "2023-11-02 11:45:38,972 - modelscope - INFO - initiate model from location C:\\Users\\junee\\.cache\\modelscope\\hub\\damo\\cv_tinynas_head-detection_damoyolo.\n",
      "2023-11-02 11:45:38,972 - modelscope - INFO - initialize model from C:\\Users\\junee\\.cache\\modelscope\\hub\\damo\\cv_tinynas_head-detection_damoyolo\n",
      "2023-11-02 11:45:40,758 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-11-02 11:45:40,758 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'train': {'mosaic_mixup': {'mosaic_prob': 1.0, 'mosaic_scale': [0.1, 2.0], 'mosaic_size': [640, 640], 'mixup_prob': 0.15, 'mixup_scale': [0.5, 1.5], 'degrees': 10.0, 'translate': 0.2, 'shear': 2.0}, 'transform': {'image_mean': [0.0, 0.0, 0.0], 'image_std': [1.0, 1.0, 1.0], 'image_max_range': [640, 640], 'flip_prob': 0.5, 'autoaug_dict': {'box_prob': 0.3, 'num_subpolicies': 5, 'scale_splits': [2048, 10240, 51200], 'autoaug_params': [6, 9, 5, 3, 3, 4, 2, 4, 4, 4, 5, 2, 4, 1, 4, 2, 6, 4, 2, 2, 2, 6, 2, 2, 2, 0, 5, 1, 3, 0, 8, 5, 2, 8, 7, 5, 1, 3, 3, 3]}}}, 'evaluation': {'transform': {'image_mean': [0.0, 0.0, 0.0], 'image_std': [1.0, 1.0, 1.0], 'image_max_range': [640, 640], 'flip_prob': 0.0}}, 'model_dir': 'C:\\\\Users\\\\junee\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\cv_tinynas_head-detection_damoyolo'}. trying to build by task and model information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is :  {'scores': array([0.83934075, 0.8387197 , 0.81702626], dtype=float32), 'labels': ['head', 'head', 'head'], 'boxes': array([[294.13876 , 125.354996, 337.02682 , 173.95854 ],\n",
      "       [507.41782 , 121.629555, 557.50665 , 178.18756 ],\n",
      "       [111.59824 , 134.82797 , 165.80174 , 195.49275 ]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "model_id = 'damo/cv_tinynas_head-detection_damoyolo'\n",
    "input_location = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/image_detection.jpg'\n",
    "\n",
    "head_detection = pipeline(Tasks.domain_specific_object_detection, model=model_id)\n",
    "result = head_detection(input_location)\n",
    "print(\"result is : \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1985c",
   "metadata": {},
   "source": [
    "## Save image with given path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c27268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(dir_path, file_name, image):\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "    cv.imwrite(file_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020d9b4",
   "metadata": {},
   "source": [
    "## Draw predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ec7b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect_with_result(input_image, result):\n",
    "    # Modify area of nametag here\n",
    "    relative_nametag_pos = [0, 10, 30, 20] #relative x0, y0, width, heigtht\n",
    "    nametag_areas = []\n",
    "    head_areas = []\n",
    "\n",
    "    image = input_image.copy()\n",
    "    \n",
    "    for id, box in enumerate(result['boxes']):\n",
    "        # Rectangel the area of human head\n",
    "        x1, y1, x2, y2 = box.astype('int')\n",
    "        head_pos = (x1, y1, x2, y2)\n",
    "        head_areas.append(head_pos)\n",
    "        cv.putText(image, str(id), (x1, y1), cv.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "        cv.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "\n",
    "        # Rectagle the area of nametag\n",
    "        cx = (x1 + x2) // 2\n",
    "        dist_x, dist_y, width, height = relative_nametag_pos\n",
    "        name_tag_pos = (cx + dist_x, y2 + dist_y, cx + dist_x + width, y2 + dist_y + height)\n",
    "        nametag_areas.append(name_tag_pos)\n",
    "\n",
    "        cv.putText(image, 'nametag', (name_tag_pos[0], name_tag_pos[1]-15), cv.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1)\n",
    "        cv.rectangle(image, name_tag_pos[0:2], name_tag_pos[2:], (0, 0, 255), 1)\n",
    "\n",
    "    # cv.imshow('Image', image)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    return image, head_areas, nametag_areas\n",
    "\n",
    "def draw_rect(input_image, head_area=None, nametag_area=None):\n",
    "    image = input_image.copy()\n",
    "    if nametag_area:\n",
    "        x1, y1, x2, y2 = nametag_area\n",
    "        cv.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        x1, y1, x2, y2 = head_area\n",
    "        cv.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    elif head_area:\n",
    "        x1, y1, x2, y2 = head_area\n",
    "        cv.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3318a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = 'images\\image0030.png'\n",
    "# img_test = cv.imread(img_path)\n",
    "# img_test = undistort_frame(img_test)\n",
    "# middle_point = 270\n",
    "# img_up, img_down = crop_image(img_test, middle_point)\n",
    "\n",
    "# cv.imshow('Up', img_up)\n",
    "# cv.imshow('Down', img_down)\n",
    "\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n",
    "\n",
    "# result1 = head_detection(img_up)\n",
    "# result2 = head_detection(img_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab19c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_detection_images(input_path=None):\n",
    "    if input_path is None:\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print('Directory not exist')\n",
    "        return\n",
    "    \n",
    "    files = os.listdir(input_path)\n",
    "    for i, file in enumerate(files):\n",
    "        i_path = os.path.join(input_path, file)\n",
    "        image = cv.imread(i_path)\n",
    "\n",
    "        # Image Preprocess\n",
    "        undistorted_image = undistort_frame(image)\n",
    "        crop_undistorted_image_up, crop_undistorted_image_down = crop_image(undistorted_image, 270)\n",
    "\n",
    "        # Head Detection\n",
    "        result1 = head_detection(crop_undistorted_image_up)\n",
    "        result2 = head_detection(crop_undistorted_image_down)\n",
    "\n",
    "        # Show result\n",
    "        crop_undistorted_image_up, _, nametag_areas1 = draw_rect_with_result(crop_undistorted_image_up, result1)\n",
    "        crop_undistorted_image_down, _, nametag_areas2 = draw_rect_with_result(crop_undistorted_image_down, result2)\n",
    "\n",
    "        # Concat image\n",
    "        crop_undistorted_image_down = cv.rotate(crop_undistorted_image_down, cv.ROTATE_180)\n",
    "        output_image = np.vstack([crop_undistorted_image_up, crop_undistorted_image_down])\n",
    "        # # Coordinate transformation\n",
    "        # vector_new = (crop_undistorted_image_down.shape[1], crop_undistorted_image_down.shape[0])\n",
    "        # new_nametag_areas2 = []\n",
    "        # for i, nametag_area2 in enumerate(nametag_areas2):\n",
    "        #     new_x1 = vector_new[0] - nametag_area2[0]\n",
    "        #     new_y1 = vector_new[1] - nametag_area2[1] + img_up.shape[0]\n",
    "        #     new_x2 = vector_new[0] - nametag_area2[2]\n",
    "        #     new_y2 = vector_new[1] - nametag_area2[3] + img_up.shape[0]\n",
    "\n",
    "        #     new_nametag_areas2.append(new_x1, new_y1, new_x2, new_y2)\n",
    "        \n",
    "\n",
    "        # Save result\n",
    "        # save_image('Head Detection Images', f'image_up{i}.jpg', crop_undistorted_image_up)\n",
    "        # save_image('Head Detection Images', f'image_down{i}.jpg', crop_undistorted_image_down)\n",
    "        # save_image(\"Head Detection Images\", f'image{i}.jpg', output_image)\n",
    "\n",
    "\n",
    "def head_detection_image(input_image):\n",
    "    image = input_image.copy()\n",
    "    # Image Preprocess\n",
    "    crop_image_up, crop_image_down = crop_image(image, 270)\n",
    "\n",
    "    # Head Detection\n",
    "    result1 = head_detection(crop_image_up)\n",
    "    result2 = head_detection(crop_image_down)\n",
    "\n",
    "    # Show result\n",
    "    crop_image_up, head_areas1, nametag_areas1 = draw_rect_with_result(crop_image_up, result1)\n",
    "    crop_image_down, head_areas2, nametag_areas2 = draw_rect_with_result(crop_image_down, result2)\n",
    "\n",
    "    # Concat image\n",
    "    crop_image_down = cv.rotate(crop_image_down, cv.ROTATE_180)\n",
    "    output_image = np.vstack([crop_image_up, crop_image_down])\n",
    "    # Coordinate transformation\n",
    "    vector_new = (crop_image_down.shape[1], crop_image_down.shape[0])\n",
    "    new_head_areas2 = []\n",
    "    new_nametag_areas2 = []\n",
    "    for i, (head_area2, nametag_area2) in enumerate(zip(head_areas2, nametag_areas2)):\n",
    "        new_x1 = vector_new[0] - head_area2[0]\n",
    "        new_y1 = vector_new[1] - head_area2[1] + crop_image_up.shape[0]\n",
    "        new_x2 = vector_new[0] - head_area2[2]\n",
    "        new_y2 = vector_new[1] - head_area2[3] + crop_image_up.shape[0]\n",
    "\n",
    "        new_head_areas2.append((new_x2, new_y2, new_x1, new_y1))\n",
    "\n",
    "        new_x1 = vector_new[0] - nametag_area2[0]\n",
    "        new_y1 = vector_new[1] - nametag_area2[1] + crop_image_up.shape[0]\n",
    "        new_x2 = vector_new[0] - nametag_area2[2]\n",
    "        new_y2 = vector_new[1] - nametag_area2[3] + crop_image_up.shape[0]\n",
    "\n",
    "        new_nametag_areas2.append((new_x2, new_y2, new_x1, new_y1))\n",
    "\n",
    "    return output_image, head_areas1 + new_head_areas2, nametag_areas1 + new_nametag_areas2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce4885af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function test\n",
    "img = cv.imread('images\\image0030.png')\n",
    "# Image Preprocess\n",
    "undistorted_image = undistort_frame(img)\n",
    "\n",
    "# Head Detection\n",
    "output_image, head_areas, nametag_areas = head_detection_image(undistorted_image)\n",
    "\n",
    "cv.imshow('Image', output_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f7259a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nametag_area in enumerate(nametag_areas):\n",
    "    nametag_img = undistorted_image[nametag_area[1]:nametag_area[3], nametag_area[0]:nametag_area[2], :] \n",
    "    cv.imshow(f'Image{i}', nametag_img)\n",
    "cv.imshow('Undistorted Image', undistorted_image)\n",
    "cv.imshow('Image', output_image)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "470ae1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nametag_detection(img, nametag_areas:np.array):\n",
    "    # Showing the nametag area and edge detection result\n",
    "    list_contours_x = []\n",
    "    list_contours_y = []\n",
    "    list_contours_xy = []\n",
    "    is_nametag_list = []\n",
    "    for idx, nametag_area in enumerate(nametag_areas):\n",
    "        nametag_img = img[nametag_area[1]:nametag_area[3], nametag_area[0]:nametag_area[2]]\n",
    "        # cv.imshow(f'NameTag{idx}', \n",
    "        #           cv.resize(nametag_img, (200, 150), interpolation=cv.INTER_AREA))\n",
    "        # Convert to graycsale\n",
    "        nametag_img_gray = cv.cvtColor(nametag_img, cv.COLOR_BGR2GRAY)\n",
    "        cv.imwrite(f'SobelImages/SourceImage{idx}.jpg', nametag_img_gray)\n",
    "        # sobelx = cv.resize(cv.Sobel(src=nametag_img_gray, ddepth=cv.CV_64F, dx=1, dy=0, ksize=3), (200, 150), interpolation=cv.INTER_AREA) # Sobel Edge Detection on the X axis\n",
    "        # sobely = cv.resize(cv.Sobel(src=nametag_img_gray, ddepth=cv.CV_64F, dx=0, dy=1, ksize=3), (200, 150), interpolation=cv.INTER_AREA) # Sobel Edge Detection on the Y axis\n",
    "        # sobelxy = cv.resize(cv.Sobel(src=nametag_img_gray, ddepth=cv.CV_64F, dx=1, dy=1, ksize=3), (200, 150), interpolation=cv.INTER_AREA)\n",
    "\n",
    "        sobelx = cv.Sobel(src=nametag_img_gray, ddepth=cv.CV_64F, dx=1, dy=0, ksize=3)\n",
    "        sobely = cv.Sobel(src=nametag_img_gray, ddepth=cv.CV_64F, dx=0, dy=1, ksize=3)\n",
    "        sobelxy = cv.Sobel(src=nametag_img_gray, ddepth=cv.CV_64F, dx=1, dy=1, ksize=3)\n",
    "\n",
    "        ret, sobelx = cv.threshold(sobelx, 100, 255, cv.THRESH_BINARY)\n",
    "        ret, sobely = cv.threshold(sobely, 100, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        # Combine sobelx, sobely\n",
    "        sobelxy = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "        # Normalization\n",
    "        sobelxy *= 255 / sobelxy.max()\n",
    "        sobelxy = sobelxy.astype(np.uint8)\n",
    "        # cv.imshow(\"Magnitude\", sobelxy)\n",
    "        \n",
    "        # cv.imshow(f'Sobel X{idx}', sobelx)\n",
    "        # cv.imshow(f'Sobel Y{idx}', sobely)\n",
    "        # cv.imshow(f'Sobel X Y using Sobel() function{idx}', sobelxy)\n",
    "\n",
    "        # Draw contour of sobelx,y,xy\n",
    "        sobelx = sobelx.astype(np.uint8)\n",
    "        sobely = sobely.astype(np.uint8)\n",
    "        sobelx_bgr = cv.cvtColor(sobelx, cv.COLOR_GRAY2BGR)\n",
    "        sobely_bgr = cv.cvtColor(sobely, cv.COLOR_GRAY2BGR)\n",
    "        sobelxy_bgr = cv.cvtColor(sobelxy, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "        contours_x, _ = cv.findContours(sobelx, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        list_contours_x.append(contours_x)\n",
    "        for contour in contours_x:\n",
    "            cv.drawContours(sobelx_bgr, [contour], -1, (0, 255, 0), 1)\n",
    "        contours_y, _ = cv.findContours(sobely, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        list_contours_y.append(contours_y)\n",
    "        for contour in contours_y:\n",
    "            cv.drawContours(sobely_bgr, [contour], -1, (0, 255, 0), 1)\n",
    "        contours_xy, _ = cv.findContours(sobelxy, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        list_contours_xy.append(contours_xy)\n",
    "        for contour in contours_xy:\n",
    "            cv.drawContours(sobelxy_bgr, [contour], -1, (0, 255, 0), 1)\n",
    "\n",
    "        # Name tag prediction\n",
    "        if len(contours_x) + len(contours_y) == 4 and len(contours_xy) == 1:\n",
    "            is_nametag_list.append(True)\n",
    "        else:\n",
    "            is_nametag_list.append(False)\n",
    "\n",
    "        # Storing sobel images for observation\n",
    "        # dir_path = 'SobelImages'\n",
    "        # file_name = 'SobelImage'\n",
    "        # os.makedirs(dir_path, exist_ok=True)\n",
    "        # path = os.path.join(dir_path, f'{file_name}')\n",
    "        # # if idx == 6:\n",
    "        # cv.imwrite(path+f'XY{idx}.jpg', sobelxy)\n",
    "        # cv.imwrite(path+f'Y{idx}.jpg', sobely)\n",
    "        # cv.imwrite(path+f'X{idx}.jpg', sobelx)\n",
    "        # cv.imwrite(path+f'X_Contour{idx}.jpg', sobelx_bgr)\n",
    "        # cv.imwrite(path+f'Y_Contour{idx}.jpg', sobely_bgr)\n",
    "        # cv.imwrite(path+f'XY_Contour{idx}.jpg', sobelxy_bgr)\n",
    "\n",
    "    return is_nametag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2a94d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junee\\AppData\\Local\\Temp\\ipykernel_10784\\1611432142.py:28: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sobelxy *= 255 / sobelxy.max()\n",
      "C:\\Users\\junee\\AppData\\Local\\Temp\\ipykernel_10784\\1611432142.py:28: RuntimeWarning: invalid value encountered in multiply\n",
      "  sobelxy *= 255 / sobelxy.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame0: X:16, Y:18\n",
      "Frame0: X:23, Y:19\n",
      "Frame0: X:22, Y:24\n",
      "Frame0: X:24, Y:25\n",
      "Frame0: X:25, Y:29\n",
      "Frame0: X:27, Y:29\n",
      "Frame0: X:32, Y:32\n",
      "Frame0: X:20, Y:17\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture('sample.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    frame_idx = 0\n",
    "    ret, frame = cap.read()\n",
    "    if ret is None:\n",
    "        break\n",
    "    # Image Preprocess\n",
    "    # undistorted_frame = undistort_frame(frame)\n",
    "\n",
    "    # Head Detection\n",
    "    output_image, head_areas, nametag_areas = head_detection_image(frame)\n",
    "\n",
    "    # Nametag Detection\n",
    "    is_nametag_list = nametag_detection(frame, nametag_areas)\n",
    "    for i, is_nametag in enumerate(is_nametag_list):\n",
    "        if is_nametag:\n",
    "            # Showing nametag image\n",
    "            # nametag_image = frame[nametag_areas[i][1]:nametag_areas[i][3], nametag_areas[i][0]:nametag_areas[i][2]]\n",
    "            # nametag_image = cv.resize(nametag_image, (nametag_image.shape[1]*10, nametag_image.shape[0]*10), interpolation=cv.INTER_AREA)\n",
    "            # cv.imshow(f'Nametag{i}', nametag_image)\n",
    "            frame = draw_rect(frame, head_areas[i], nametag_areas[i])\n",
    "            print(f'Frame{frame_idx}: X:{(head_areas[i][2] - head_areas[i][0]) // 2}, Y:{(head_areas[i][3] - head_areas[i][1]) // 2}')\n",
    "        else:\n",
    "            frame = draw_rect(frame, head_areas[i])\n",
    "            \n",
    "    cv.imshow('Frame', frame)\n",
    "    # cv.imshow('Output', output_image)\n",
    "    if cv.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
